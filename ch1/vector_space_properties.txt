## conventions
- in future mentions V will by default denote a vector space over F
- parentheses in addition can be omitted because of associativity
	- (u + v) + w = u + (v + w) = u + v + w

## vector space properties
- [1.2] a vector space's additive identity is unique
	- by definition a vector space has an additive identity, but this proposes that it is unique
	- suppose 0 and 0' are both additive identities for some vector space V
		- 0' = 0' + 0 because 0 is an additive identity
		- 0 = 0 + 0' because 0' is an additive identity
		- 0' + 0 = 0 + 0' by commutivity
		- so 0 = 0' and there is only 1
- [1.3] each element v in a vector space has a unique additive identity
	- by definition each element has an additive identity, but this proposes that it is unique
	- suppose w and w' are additive inverses of v E V
		- w = w + 0 by the existence of an additive identity in V
		- w + 0 = w + (v + w') because w' is an additive inverse of v
		- w + (v + w') = (w + v) + w' by associativity of addition on V
		- (w + v) + w' = 0 + w' = w' because w is an additive inverse of v
		- so w = w' and there is only 1
	- because additive inverses are unique, -v can denote the additive inverse of v
		- w - v is defined to mean w + (-v)
- [1.4] 0v = 0 for every v E V
	- product of scalar 0 and any vector is the vector 0
	- the distributive property is the only part of V's definition connecting scalar
	  multplication and vector addition so it must be used in this proof
	- 0v = (0 + 0)v because 0 is the additive identity in F
	- (0 + 0)v = 0v + 0v by distribution over scalar multiplication
	- 0v = 0v + 0v 
	- 0v - 0v = 0v + 0v - 0v by existence of additive inverse
	- 0 = 0v 
- [1.5] a0 = 0 for every a E F
	- product of any scalar and vector 0 is the vector 0
	- a0 = a(0 + 0) because 0 is the additive identity in V
	- a(0 + 0) = a0 + a0 by distribution over scalar multiplication
	- a0 = a0 + a0
	- a0 - a0 = a0 + a0 - a0 by existence of additive inverse
	- 0 = a0
- [1.6] (-1)v = -v for every v E V
	- scalar multiplication by -1 gives the additive inverse of any vector
	- v + (-1)v = 1v + (-1)v 
	- (1 + (-1))v by distribution
	- = 0v = 0 by proposition 1.4
	- adding (-1)v to v gives 0, making it by definition the additive inverse of v


## subspaces
- a subset U of V is a subspace of V if U is also a vector space using the same addition and multiplication
	- {(x1,x2,0) : x1, x2 E F} is a subspace of F3
- simplified checks that it's a vector space if U is a subset of V
	- additive identity 0 E U
		- ensure the additive identity of V is in U
	- closed under addition u,v E U --> u + v E U
		- addition makes sense on U
	- closed under scalar multiplication a E F and u E U --> au E U
		- scalar multiplication makes sense on U
- ex. {(x1, x2, x3, x4) E F4 : x3 = 5*x4 + b} is a subset of F4 for b E F
	- additive identity
		- since it's a subset of F4, we know the additive identity is (0,0,0,0)
		- x3 = 5*x4 + b = 5*0 + b = b = 0 so b must be 0 for the additive identity to exist
	- closed under addition
		- (x1, x2, x3, x4) + (y1, y2, y3, y4) = (x1 + y1, x2 + y2, x3 + y3, x4 + y4)
		- x3 + y3 = 5*x4 + b + 5*y4 + b by definition
		- = 5*(x4 + y4) + 2b by distribution
		- the condition requires x3 + y3 = 5*(x4 + y4) + b
		- this only holds if b = 2b, which is only satisfied by b = 0
	- closed under scalar multiplication
		- a(x1, x2, x3, x4) = (a*x1, a*x2, a*x3, a*x4)
		- a*x3 = a(5*x4 + b) by definition
		- = 5*(a*x4) + a*b by distribution
		- the condition requires a*x3 = 5*(a*x4) + b
		- so a*b = b for all a E F
		- only true of b = 0
	- so is subspace if b = 0
- ex. {p E P(F) : p(3) = 0} is a subspace of P(F)
	- additive identity
		- since it's a subset of P(F), we know the additive identity is ai = 0 for i = 0,...,m
		- this exists in the subset because 0(3) = 0
	- closed under addition
		- only need to consider when field is 3
		- (p + q)(3) = p(3) + q(3) by definition of P(F)
		- = 0 + 0 = 0 as required to remain in the subset
	- closd under scalar multiplication
		- (ap)(z) = ap(z) by definition of P(F)
		- consider z = 3
		- (ap)(3) = ap(3)
		- = a*0 = 0 as required to remain in the subset
- subspaces of R2
	- {0}
	- R2
	- all lines in R2 through the origin
- subspaces of R3
	- {0}
	- R3
	- all lines in R3 through the origin
	- all planes in R3 through the origin
- proving some subset is a subspace is easy, but proving they are the only subspaces is hard

## sums
- suppose U1,...,Um are subspaces of V
- sum of U1,...,Um
	- denoted at U1 + ... + Um
	- defined as set of all possible sums of elements of U1,...,Um
		- U1 + ... + Um = {u1 + ... + um : u1 E U1,...,um E Um}
	- the sum of subspaces is still a subspace
		- the sum must be a subset of V because V is closed under addition
			- V is a subspace of V, which must be closed under addition
		- additive identity
			- we need only one subspace that contains the additive identity for it to be in the sum
			- U1,...,Um each contains the additive identity of V since they are subspaces
			- therefore the additive identity must be in the sum
		- closed under addition
			- let a = u1 + ... + um be one element of the sum
			- let b = v1 + ... + vm be another element of the sum
			- a + b = (u1 + ... + um) + (v1 + ... + vm)
			- = (u1 + v1) + ... + (um + vm) gather vectors of the same subspace, allowed due to commutivity
			- = s1 + ... + sm where si E Ui since each subspace is closed under addition
			- this is by definition an element of the sum
		- closed under scalar multiplication
			- very similar argument to addition
- the sum is the smallest subspace containing the summed subspaces
	- analogy to union of set theory
	- U1,...,Um are subpsaces of V
		- U1,...,Um are all contained in U1 + ... + Um
			- consider sums u1 + ... + um where all except one element are 0
		- any subspace containing U1,...,Um must contain U1 + ... + Um
			- to be closed under addition, subspaces must contain all finite sums of their elements
- examples
	- U = {(x,0,0) E F3 : x E F} and W = {(0,y,0) E F3 : y E F}
		- [1.8] U + W = {(x,y,0) : x,y E F}
	- U = {(x,0,0) E F3 : x E F} and W = {(y,y,0) E F3 : y E F}
		- U + W = {(x,y,0) : x,y E F}

## direct sums
- suppose V = U1 + ... + Um
	- every element can be written as u1 + ... + um, uj E Uj
	- when each vector in V can be **uniquely** represented so, it is called a direct sum
	- V is the direct sum of subspaces U1,...,Um
		- V = U1 ++ ... ++ Um (can't represent \oplus in text, but it's a + inscribed in a circle)
- examples
	- let U = {(x,y,0) E F3 : x,y E F} and W = {(0,0,z) E F3 : z E F}
		- F3 = U ++ W
			- the subspaces cannot have any shared elements since then there'd the multiple ways to sum to the same element
	- let Ue be the subspace of P(F) of the form p(z) = a0 + a2*z^2 + ... + a2m*z^(2m)
	  and Uo be the subspace with p(z) = a1*z + a3*z^3 + ... + a_(2m+1)*z^(2m+1)
		- m is a nonnegative integer
		- a0,...,a_(2m+1) E F
		- Ue and Uo are even and odd powers of z
		- P(F) = Ue ++ Uo
- non-example
	- let U1 = {(x, y, 0) E F3 : x, y E F} U2 = {(0, 0, z) E F3 : z E F} U3 = {(0, y, y) E F3 : y E F}
- [1.8] given U1,...,Un are subspaces of V, then V = U1 ++ ... ++ Un iff
	a) V = U1 + ... + Un
	b) the only way to write 0 as a sum u1 + ... + un where uj E Uj is setting all uj = 0
	- prove by considering the forward and backward direction
		- given V = U1 ++ ... ++ Un
			- clearly a) holds from the direct sum's definition
			- 0 = u1 + .. + un implies uj = 0 because direct sum elements must be unique
		- given a) and b)
			- v = u1 + ... + un (where v E V) by a)
			- suppose also v = v1 + ... + vn
			- 0 = (u1 - v1) + ... + (uv - vn)
			- by b), (uj - vj) = 0 for all j, so uj = vj and we have our uniqueness
- [1.9] given U and W are subspaces of V, V = U ++ W iff V = U + W and U intersect W = {0}
	- only in the case of two subspaces
	- with more it's not enough to just consider this property pairwise
	- prove by considering the forward and backward direction
		- given V = U ++ W
			- V = U + W by definition of direct sum
			- if v E (U intersect W) then 0 = v + (-v) (why can this be the only element of the intersect set?)
				- v E U
				- (-v) E W
				- element has to be expressable as sum of single, separate subspace elements
			- because 0 must have a unique representation as a sum, v = 0 [1.8]
			- thus U intersect W = {0}
			- this is the textbook proof, but I think its easier to think that if U intersect W had element u in addition to 0, then we can represent u E V non-uniquely as u + 0 and 0 + u, contradicting direct sum's definition
		- given V = U + W and U intersect W = {0}
			- suppose 0 = u + w
			- u = -w, so u E W [1.6] (inverse always exists inside vector space)
			- u E (U intersect W) because u E U and u E W
			- u = 0 = w because U intersect W = {0}
			- V = U ++ W by [1.8]